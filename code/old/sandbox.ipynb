{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/aakash/anaconda3/envs/gis/lib/python3.6/site-packages')\n",
    "sys.path.append('/Users/aakash/anaconda3/lib/python3.6/site-packages')\n",
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from itertools import product\n",
    "import time\n",
    "#import geopandas as gp\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "warnings.filterwarnings('ignore')\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_landsat(year):\n",
    "    \n",
    "    '''\n",
    "    select the appropriate landsat based on years of operation \n",
    "    '''\n",
    "    \n",
    "    landsats = {\"L4\":ee.ImageCollection('LANDSAT/LT04/C01/T1_SR'), \n",
    "            \"L5\": ee.ImageCollection('LANDSAT/LT05/C01/T1_SR'),\n",
    "            \"L7\":ee.ImageCollection('LANDSAT/LE07/C01/T1_SR'),\n",
    "            \"L8\":ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")}\n",
    "    \n",
    "    if year < 1982 : \n",
    "        print(\"No landsat available\")\n",
    "    if year < 1993 and year > 1982:\n",
    "        landsat = landsats['L4']\n",
    "    if year < 2012 and year >1993:\n",
    "        landsat = landsats['L5']\n",
    "    else: \n",
    "        landsat = landsats['L8']\n",
    "        \n",
    "    return landsat\n",
    "\n",
    "def get_sentinel(year):\n",
    "    '''\n",
    "    Return Sentinel SAR image collection\n",
    "    '''\n",
    "    \n",
    "    return ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "    \n",
    "def calc_end_date(sampling_int, year,month,day, sampling_freq = 1):\n",
    "    \n",
    "    '''\n",
    "    given a start date and sampling interval, advance 1 interval and return the end date\n",
    "    \n",
    "    sampling int: str, ex: \"week\"\n",
    "    '''\n",
    "    start = ee.Date.fromYMD(year,month,day)\n",
    "    if sampling_int == \"day\":\n",
    "        end = start.advance(sampling_freq,\"day\")\n",
    "    if sampling_int == \"week\":\n",
    "        end = start.advance(sampling_freq,\"week\")\n",
    "    if sampling_int == \"month\":\n",
    "        end = start.advance(sampling_freq,\"month\")\n",
    "    if sampling_int == \"year\":\n",
    "        end = start.advance(sampling_freq,\"year\")\n",
    "    return start,end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_QA_bits(image, start, end, field_name):\n",
    "    \n",
    "    '''\n",
    "    retrieve quality bits from landsat\n",
    "    '''\n",
    "    \n",
    "    pattern = 0\n",
    "    for i in range(start,end+1):\n",
    "        pattern += 2**i\n",
    "    return image.select([0], [field_name]).bitwiseAnd(pattern).rightShift(start)\n",
    "\n",
    "def mask_quality(image):\n",
    "    \n",
    "    '''\n",
    "    mask clouds and shadows from landsat\n",
    "    '''\n",
    "    \n",
    "    QA = image.select('pixel_qa')\n",
    "    # Get the internal_cloud_algorithm_flag bit.\n",
    "    shad = get_QA_bits(QA,3,3,'cloud_shadow')\n",
    "    cloud = get_QA_bits(QA,5,5,'cloud')\n",
    "    cirrus_detected = get_QA_bits(QA,9,9,'cirrus_detected')\n",
    "    #Return an image masking out cloudy areas.\n",
    "    return image.updateMask(shad.eq(0)).updateMask(cloud.eq(0).updateMask(cirrus_detected.eq(0))).unmask()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_from_col(col,band,res,start,end,bounds):\n",
    "    \n",
    "    '''\n",
    "    Transform an ee.ImageCollection class to a numpy array. The ee.ImageCollection should be filtered for date, area, and cloud masked. \n",
    "    \n",
    "    Args: \n",
    "    \n",
    "    col: ee.ImageColletion ex 'LANDSAT/LT04/C01/T1_SR'\n",
    "    band: string, ex \"B1\" \n",
    "    res: int, ex: 30\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get the lat lon and add the band and scale by the appropriate factor (0.0001 for landsat)\n",
    "    band_name = col.select(band).median()\n",
    "    latlon = ee.Image.pixelLonLat().addBands(band_name).multiply(0.0001)\n",
    "\n",
    "    # apply reducer to list\n",
    "    latlon = latlon.reduceRegion(\n",
    "      reducer=ee.Reducer.toList(),\n",
    "      geometry=bounds,\n",
    "      maxPixels=1e13,\n",
    "      scale=res)\n",
    "    \n",
    "    data = np.array((ee.Array(latlon.get(band)).getInfo()))\n",
    "    lats = np.array((ee.Array(latlon.get(\"latitude\")).getInfo()))\n",
    "    lons = np.array((ee.Array(latlon.get(\"longitude\")).getInfo()))\n",
    "    \n",
    "    arr = array_from_coords(data,lats,lons)\n",
    "    \n",
    "    return (arr)\n",
    "\n",
    "def array_from_coords(data,lats,lons):\n",
    "    \n",
    "    '''\n",
    "    Return a numpy array from lats, lons, and data values (ie cartesian product) \n",
    "    '''\n",
    "    \n",
    "    # get the unique coordinates\n",
    "    uniqueLats = np.unique(lats)\n",
    "    uniqueLons = np.unique(lons)\n",
    "\n",
    "    # get number of columns and rows from coordinates\n",
    "    ncols = len(uniqueLons)    \n",
    "    nrows = len(uniqueLats)\n",
    "\n",
    "    # determine pixelsizes\n",
    "    ys = uniqueLats[1] - uniqueLats[0] \n",
    "    xs = uniqueLons[1] - uniqueLons[0]\n",
    "\n",
    "    # create an array with dimensions of image\n",
    "    arr = np.zeros([nrows, ncols], np.float32) #-9999\n",
    "\n",
    "    # fill the array with values\n",
    "    counter =0\n",
    "    for y in range(0,len(arr),1):\n",
    "        for x in range(0,len(arr[0]),1):\n",
    "            if lats[counter] == uniqueLats[y] and lons[counter] == uniqueLons[x] and counter < len(lats)-1:\n",
    "                counter+=1\n",
    "                arr[len(uniqueLats)-1-y,x] = data[counter] \n",
    "                \n",
    "    return arr\n",
    "\n",
    "def gen_polys(geometry, dx, dy):\n",
    "    \n",
    "    '''\n",
    "    Return ee.ImaceCollection of polygons used to submit full res (30m landsat; 10m sentinel) resolution\n",
    "    '''\n",
    "    \n",
    "    bounds = ee.Geometry(geometry).bounds()\n",
    "    coords = ee.List(bounds.coordinates().get(0))\n",
    "    ll = ee.List(coords.get(0))\n",
    "    ur = ee.List(coords.get(2))\n",
    "    xmin = ll.get(0)\n",
    "    xmax = ur.get(0)\n",
    "    ymin = ll.get(1)\n",
    "    ymax = ur.get(1)\n",
    "\n",
    "    latlist = ee.List.sequence(ymin, ymax, dx)\n",
    "    lonlist = ee.List.sequence(xmin, xmax, dy)\n",
    "    \n",
    "    polys = []\n",
    "    \n",
    "    for lon in lonlist.getInfo():\n",
    "        for lat in latlist.getInfo():\n",
    "        \n",
    "            def make_rect(lat, lon):\n",
    "                lattemp = ee.Number(lat)\n",
    "                lontemp = ee.Number(lon)\n",
    "                uplattemp = lattemp.add(dy)\n",
    "                lowlontemp = lontemp.add(dx)\n",
    "\n",
    "                return ee.Feature(ee.Geometry.Polygon([[lontemp, lattemp],[lowlontemp, lattemp],[lowlontemp, uplattemp],[lontemp, uplattemp]]))\n",
    "            \n",
    "            poly = make_rect(lat,lon)\n",
    "            polys.append(poly)\n",
    "    \n",
    "    return ee.FeatureCollection(ee.List(polys))\n",
    "\n",
    "def get_nrows_ncols(geometry, dx, dy):\n",
    "    \n",
    "    '''\n",
    "    Return a list of ee.Geometry class polygons that can be used to submit full resolution queries\n",
    "    '''\n",
    "    bounds = ee.Geometry(geometry).bounds()\n",
    "    coords = ee.List(bounds.coordinates().get(0))\n",
    "    ll = ee.List(coords.get(0))\n",
    "    ur = ee.List(coords.get(2))\n",
    "    xmin = ll.get(0)\n",
    "    xmax = ur.get(0)\n",
    "    ymin = ll.get(1)\n",
    "    ymax = ur.get(1)\n",
    "\n",
    "    latlist = ee.List.sequence(ymin, ymax, dx)\n",
    "    lonlist = ee.List.sequence(xmin, xmax, dy)\n",
    "    \n",
    "    return latlist.getInfo(), lonlist.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Study area (upoad kml to google fusion table, use the DocID in the ft string below)\n",
    "area = (ee.FeatureCollection('ft:1QPasan0i6O9uUlcYkjqj91D7mbnhTZCmzS4t7t_g').filter(ee.Filter.eq('id', '107')))\n",
    "bounds = area.geometry().bounds()\n",
    "\n",
    "# Set the study years\n",
    "# years = [x for x in range(2000, 2018)] # 2000 - 2015\n",
    "year = 2016\n",
    "month = 7\n",
    "day = 1\n",
    "sampling_int = \"week\"\n",
    "sampling_freq = 3\n",
    "start, end = calc_end_date(sampling_int, year, month, day, sampling_freq)\n",
    "res = 30\n",
    "band = \"B1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = get_landsat(year).filterBounds(bounds).filterDate(start, end).map(mask_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx, dy = 0.15, 0.15\n",
    "polys = gen_polys(bounds, dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = polys.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting AOI region in to 36 polygons\n"
     ]
    }
   ],
   "source": [
    "print(\"Subsetting AOI region in to {} polygons\".format(len(temp['features'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: \n",
      "[[-119.5784, 35.7879], [-119.4284, 35.7879], [-119.4284, 35.9379], [-119.5784, 35.9379], [-119.5784, 35.7879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.5784, 35.9379], [-119.4284, 35.9379], [-119.4284, 36.0879], [-119.5784, 36.0879], [-119.5784, 35.9379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.5784, 36.0879], [-119.4284, 36.0879], [-119.4284, 36.2379], [-119.5784, 36.2379], [-119.5784, 36.0879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.5784, 36.2379], [-119.4284, 36.2379], [-119.4284, 36.3879], [-119.5784, 36.3879], [-119.5784, 36.2379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.5784, 36.3879], [-119.4284, 36.3879], [-119.4284, 36.5379], [-119.5784, 36.5379], [-119.5784, 36.3879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.5784, 36.5379], [-119.4284, 36.5379], [-119.4284, 36.6879], [-119.5784, 36.6879], [-119.5784, 36.5379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.4284, 35.7879], [-119.2784, 35.7879], [-119.2784, 35.9379], [-119.4284, 35.9379], [-119.4284, 35.7879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.4284, 35.9379], [-119.2784, 35.9379], [-119.2784, 36.0879], [-119.4284, 36.0879], [-119.4284, 35.9379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.4284, 36.0879], [-119.2784, 36.0879], [-119.2784, 36.2379], [-119.4284, 36.2379], [-119.4284, 36.0879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.4284, 36.2379], [-119.2784, 36.2379], [-119.2784, 36.3879], [-119.4284, 36.3879], [-119.4284, 36.2379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.4284, 36.3879], [-119.2784, 36.3879], [-119.2784, 36.5379], [-119.4284, 36.5379], [-119.4284, 36.3879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.4284, 36.5379], [-119.2784, 36.5379], [-119.2784, 36.6879], [-119.4284, 36.6879], [-119.4284, 36.5379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.2784, 35.7879], [-119.1284, 35.7879], [-119.1284, 35.9379], [-119.2784, 35.9379], [-119.2784, 35.7879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.2784, 35.9379], [-119.1284, 35.9379], [-119.1284, 36.0879], [-119.2784, 36.0879], [-119.2784, 35.9379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.2784, 36.0879], [-119.1284, 36.0879], [-119.1284, 36.2379], [-119.2784, 36.2379], [-119.2784, 36.0879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.2784, 36.2379], [-119.1284, 36.2379], [-119.1284, 36.3879], [-119.2784, 36.3879], [-119.2784, 36.2379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.2784, 36.3879], [-119.1284, 36.3879], [-119.1284, 36.5379], [-119.2784, 36.5379], [-119.2784, 36.3879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.2784, 36.5379], [-119.1284, 36.5379], [-119.1284, 36.6879], [-119.2784, 36.6879], [-119.2784, 36.5379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.1284, 35.7879], [-118.9784, 35.7879], [-118.9784, 35.9379], [-119.1284, 35.9379], [-119.1284, 35.7879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.1284, 35.9379], [-118.9784, 35.9379], [-118.9784, 36.0879], [-119.1284, 36.0879], [-119.1284, 35.9379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.1284, 36.0879], [-118.9784, 36.0879], [-118.9784, 36.2379], [-119.1284, 36.2379], [-119.1284, 36.0879]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.1284, 36.2379], [-118.9784, 36.2379], [-118.9784, 36.3879], [-119.1284, 36.3879], [-119.1284, 36.2379]]\n",
      "===== FIN ========== FIN ========== FIN =====\n",
      "Processing: \n",
      "[[-119.1284, 36.3879], [-118.9784, 36.3879], [-118.9784, 36.5379], [-119.1284, 36.5379], [-119.1284, 36.3879]]\n"
     ]
    }
   ],
   "source": [
    "arrs = []\n",
    "\n",
    "for i in temp['features']:\n",
    "    rounded = [list(np.round(x,4) for x in i['geometry']['coordinates'][0])]\n",
    "    r = [list(x) for x in rounded[0]]\n",
    "    print(\"Processing: \")\n",
    "    print(r)\n",
    "    aoi = ee.Geometry.Polygon(r)\n",
    "    arrs.append(array_from_col(col, band, res = 30,start = start, end = end, bounds = aoi))\n",
    "    print(\"===== FIN =====\" * 3)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in arrs:\n",
    "    plt.imshow(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rows_cols(polys):\n",
    "    centroids = []\n",
    "\n",
    "    for i in polys:\n",
    "        centroids.append(ee.Geometry.Polygon(i['geometry']['coordinates']).centroid().getInfo())\n",
    "    \n",
    "    all_coords = [d['coordinates'] for d in centroids]\n",
    "    lons = [x[0] for x in all_coords]\n",
    "    lats = [x[1] for x in all_coords]\n",
    "    flats = [ '%.2f' % elem for elem in lats]\n",
    "    flons = [ '%.2f' % elem for elem in lons]\n",
    "    nrows = len(np.unique(flats))\n",
    "    ncols = len(np.unique(flons))\n",
    "    \n",
    "    return nrows, ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_rows_cols(temp['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "\n",
    "1. Chunk grid to get full resolution [X]\n",
    "\n",
    "2. Try out ee.Reducer.ToCollection\n",
    "3. MODIS cloud masks \n",
    "4. Sentinel (optical) cloud masks and Sentinel Radar \n",
    "5. Landcover code \n",
    "\n",
    "Make it OOP!!!!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the RS products\n",
    "collection = ee.ImageCollection('COPERNICUS/S1_GRD').filterBounds(bounds).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')).select('VV')\n",
    "t = collection.filterDate(start, end).mosaic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im2 = array_from_col(t, res = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im2)\n",
    "plt.axis(\"off\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Chunk check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dx, dy = 0.05, 0.05\n",
    "temp = gen_polys(bounds, dx, dy)\n",
    "polys = temp.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_arrs = []\n",
    "\n",
    "for i in polys:\n",
    "    print(i['geometry']['coordinates'])\n",
    "    aoi = ee.Geometry.Polygon(i['geometry']['coordinates'])\n",
    "    s1_arrs.append(array_from_col(t,res = 10, bounds = aoi))\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in s1_arrs:\n",
    "    plt.imshow(i, cmap = \"terrain\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIS (done) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the study years\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the Study area (upoad kml to google fusion table, use the DocID in the ft string below)\n",
    "area = (ee.FeatureCollection('ft:1QPasan0i6O9uUlcYkjqj91D7mbnhTZCmzS4t7t_g').filter(ee.Filter().eq('id', '107')))\n",
    "bounds = area.geometry().bounds()\n",
    "\n",
    "# Set the satellite data of interest\n",
    "modis_ndvi = ee.ImageCollection('MCD43A4_NDVI')\n",
    "modis_lc = ee.ImageCollection('MODIS/006/MCD12Q1')\n",
    "modis_sr = ee.ImageCollection('MCD43A4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sr = ees.filter_modis_sr(year)\n",
    "lc = ees.filter_modis_lc(year)\n",
    "\n",
    "clipped_sr = ee.ImageCollection(sr.clip(bounds))\n",
    "clipped_lc = ee.ImageCollection(lc.clip(bounds))\n",
    "\n",
    "lc_out = clipped_lc.getRegion(bounds,250,\"epsg:4326\").getInfo()\n",
    "sr_out = clipped_sr.getRegion(bounds,250,\"epsg:4326\").getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tulare = eef.df_from_imcol(sr_out)\n",
    "tulare_lc = eef.df_from_imcol(lc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bandnames = [\"Nadir_Reflectance_Band1\",\"Nadir_Reflectance_Band2\",\"Nadir_Reflectance_Band3\", \"Nadir_Reflectance_Band4\", \"Nadir_Reflectance_Band5\",\"Nadir_Reflectance_Band6\", \"Nadir_Reflectance_Band7\"]\n",
    "\n",
    "ims = []\n",
    "for b in bandnames:\n",
    "    ims.append(eef.array_from_df(tulare,b))\n",
    "\n",
    "lcs = [\"LC_Type1\"]\n",
    "ims.append(eef.array_from_df(tulare_lc,lcs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "for i in range(len(ims)):\n",
    "    spidx = i+1\n",
    "    plt.subplot(4,2,spidx)\n",
    "    try:\n",
    "        plt.title(\"{}\".format(bandnames[i]))\n",
    "    except:\n",
    "        plt.title(\"crop mask\")\n",
    "    plt.imshow(ims[i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab the training data \n",
    "cwd = os.getcwd() #os.path.split(os.getcwd())[0]\n",
    "y_dir = [os.path.join(cwd,x) for x in os.listdir(cwd) if \"yield\" in x][0]\n",
    "fn = [os.path.join(y_dir,x) for x in os.listdir(y_dir) if \"107\" in x][0]\n",
    "\n",
    "d = json.load(open(fn))\n",
    "yrs = [str(x) for x in years]\n",
    "d_2 = { year: d[year] for year in yrs }\n",
    "training = d_2.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array([np.ndarray.flatten(x) for x in ims])\n",
    "labels = np.array(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ML methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 10)\n",
    "\n",
    "# NN naming convention\n",
    "X_train = np.array(train_features)\n",
    "X_test = np.array(test_features)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ff_nn(X_train):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(85, input_dim=33150, activation='relu'))\n",
    "    model.add(Dense(42, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize loss functions\n",
    "plot_callback = PlotLossesKeras()\n",
    "\n",
    "# Fit model\n",
    "model = ff_nn(X_train)\n",
    "model.fit(X_train, y_train, validation_data=[test_features,test_labels],epochs=300,verbose=1, callbacks = [plot_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test).reshape(predictions.shape[0])\n",
    "mape = 100. * (np.abs((predictions - y_test) / y_test))\n",
    "np.mean(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate, train, predict \n",
    "rf = RandomForestRegressor(n_estimators= 10000)#, random_state=50)\n",
    "rf.fit(train_features, train_labels);\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# rf_new = RandomForestRegressor(n_estimators = 500, criterion = 'mse', max_depth = None, min_samples_split = 2, min_samples_leaf = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Median Absolute Percentage Error Function\n",
    "mape = 100 * (np.abs(((predictions) - (test_labels)) / (test_labels)))\n",
    "\n",
    "print('Median Absolute Percentage Error: {} %'.format(str(round(np.median(mape), 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = rf.feature_importances_\n",
    "s.reshape(arrs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(s.reshape(arrs[0].shape))\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(arrs[0])\n",
    "\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
